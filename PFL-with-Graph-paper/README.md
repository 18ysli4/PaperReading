# Personalized Federated Learning With a Graph

## 1.摘要、介绍与相关工作
### 1.1 这篇文章在什么背景下解决了什么问题？现有的方法有什么问题？作者有什么贡献？

**背景与问题：**文章在联邦学习（Federated Learning，FL）的背景下提出了一种新的解决方案。联邦学习是一种协作式的机器学习框架，它的目标是在保护用户隐私的同时进行模型的训练和更新。然而，传统的FL方法，例如FedAvg，面临着非独立同分布（non-IID）的挑战。目前，已有的研究要么试图在服务端训练一个鲁棒的模型以解决非IID的问题，要么尝试学习多个全局模型或者为每个客户端学习特定的模型。但这些方法在知识共享和模型个性化的实现上有所不足，特别是在非IID程度很高的情况下，全局模型的质量可能较低，进而影响模型个性化的性能。

**现有方法的问题：**现有的个性化FL方法在模型个性化的改进上做了很多工作，但在知识共享的实现上，它们通常只是简单地聚合所有的本地模型。这样的实现忽视了具有非IID数据的客户之间的图关系。此外，如果非IID的程度非常高，所有客户的聚合将产生一个质量低下的全局模型，最终影响模型个性化的性能。

**作者的贡献：**作者提出了一种新的结构化联邦学习（Structured Federated Learning，SFL）方法，利用客户间的关系图来增强个性化FL。作者设计了一种细粒度的模型聚合机制，利用每个客户邻居的本地模型。此外，作者提出使用图卷积网络（Graph Convolutional Network，GCN）实现模型聚合功能，从而使得这种解决方案易于实现。作者还将问题描述为一个统一的优化框架，既包括个性化FL，也包括基于图的模型聚合。此外，作者的方法已经扩展到学习客户之间的隐藏关系，并且概念框架可以扩展以与其他模型个性化技术集成。最后，作者在图像和交通数据集上的实验验证了所提方法的有效性。
### 1.2 在文章的Introduction中提到clients的关系图是保存在server端的，这是否会泄露用户的隐私？
在联邦学习的背景下，客户端的关系图被保存在服务器端并不一定会导致用户隐私的泄露。这主要取决于关系图中包含的具体信息以及如何使用和保护这些信息。

关系图是一种表现不同数据源之间关联性的方式，而并不直接存储用户的个人信息。例如，关系图可能描述的是哪些客户端有相似的数据分布，而不是特定的个人数据。关系图帮助服务器更好地理解数据的结构，并指导模型的训练，以提高模型的性能。

然而，如果关系图包含可以被追溯到个人的敏感信息，或者被不当使用，确实存在泄露用户隐私的风险。因此，创建和使用关系图应遵循数据最小化和隐私保护的原则。例如，可以使用技术手段（如差分隐私或安全多方计算）来保护关系图中的信息，以防止潜在的隐私泄露。在具体实施过程中，也需要考虑适用的法律法规，例如GDPR在欧洲的实施，对于用户数据的处理都有严格的要求。

总的来说，虽然客户端关系图被存储在服务器端可能存在一定的隐私风险，但是通过正确的数据管理和保护手段，可以有效地控制这些风险。
### 1.3 现有的个性化联邦学习方法主要有哪两种？
现有的个性化联邦学习方法主要有两种：集群式个性化联邦学习（Group-wise PFL）和客户端个性化联邦学习（Client-wise PFL）。

1. **集群式个性化联邦学习（Group-wise PFL）：**这种方法也被称为集群化联邦学习，它假设客户可以被聚类到具有严重非IID特性的不同组中。因此，根据不同的聚类方法和距离度量，可以将集群化的FL进行分类。例如，Kmeans-based集群化FL [Xie et al., 2021] 和 [Mansour et al., 2020; Ghosh et al., 2020] 分别使用模型参数和准确度来度量距离。另外，层次聚类方法（Hierarchical clustering）[Briggs et al., 2020]也被应用到联邦学习中。此外，[Ma et al., 2022] 提出了一种通用的形式来将集群化FL问题模型化为一个双层优化框架，然后利用客户之间的重要贡献来形成一个基于权重的客户端集群化FL框架。
2. **客户端个性化联邦学习（Client-wise PFL）：**这种方法通常假设每个客户的数据分布与其他客户的数据分布不同，因此，每个客户应该在其设备上有一个个性化的模型。一般来说，一个简单的PFL方法可以在FedAvg中训练一个全局模型，然后在每个客户端上进行几步微调 [Cheng et al., 2021]。在这个框架中，知识共享是模型聚合，模型个性化是本地微调。Per-FedAvg [Fallah et al., 2020] 认为微调是全局模型学习目标函数的一个正则化项。Ditto [Li et al., 2021] 被提出作为一个考虑约束局部模型和全局模型之间距离的正则化项的PFL的双层优化框架。此外，有些研究 [Shamsian et al., 2021; Chen et al., 2018] 旨在训练一个全局超网络或元学习器，而不是一个全局模型，然后将其发送给客户进行本地优化。SCAFFOLD [Karimireddy et al., 2020] 提出学习个性化的控制变量来根据需要修正本地模型。逐层个性化 [Arivazhagan et al., 2019; Liang et al., 2020] 和表示层个性化[Tan et al., 2021] 是PFL的两种简单但有效的解决方案。

### 1.4 为什么Per-FedAvg方法将微调过程视为全局模型学习目标函数的一个正则化项
在机器学习中，正则化是一种防止模型过拟合的技术，它通过向模型的目标函数添加一个额外的惩罚项来约束模型的复杂度，使模型对训练数据的拟合程度和模型复杂度之间达到某种平衡。这个额外的惩罚项就被称为正则化项。

在Per-FedAvg中，这个正则化项就是微调过程。在这里，微调是指在已经训练好的全局模型基础上，进一步根据每个客户端的本地数据进行优化，以适应每个客户端的特定需求。将微调视为一个正则化项，可以帮助约束全局模型在每个客户端的本地数据上的表现，从而在全局模型和个性化模型之间找到一个平衡。

简单来说，这就是将全局模型的微调过程看作是一个正则化项，从而在全局和个性化之间找到平衡，避免模型在某些客户端数据上过度拟合，同时在其他客户端数据上表现不佳。
